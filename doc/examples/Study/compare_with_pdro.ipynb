{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparison with the python-dro package\n\n.. admonition:: TLDR\n\n   A new toolbok appeared for general DRO. Their support for Wasserstein\n   ambiguity sets is limited to certain specific models; ``SkWDRO`` is thus\n   complementary to it.\n   In the intersection of our two playgrounds, one can find (regularized) WDRO\n   linear regressions. So we run a quick comparison notebook below.\n   In short: both get similar accuracy performances, but ``SkWDRO`` often yields\n   similar or better running times.\n\nIn December 2023, the library [python-dro](https://python-dro.org) was released\nby a team of experts of Distributionally Robust Optimisation.\nIt tackles a **very** wide range of ambiguity sets (for Maximum-Mean-Discrepancy,\nKL, etc). They propose both the Wasserstein ambiguity set as well as its\nSinkhorn-regularized counterpart.\nThe version [0.3.3](https://github.com/namkoong-lab/dro/releases/tag/v0.3.3)_\nof their repository is limited to what follows:\n\n.. As us authors of ``SkWDRO`` were developping this library, an amazing new challenger has appeared in the scene of libraries for distributionally robust optimization: [python-dro](https://python-dro.org) emerged to tackle a **very** wide range of ambiguity sets (as we explain in the [wdro tutorial](wdro.html#distributional-robustness-divergences)_), and they propose both the Wasserstein ambiguity set as well as its Sinkhorn regularized counterpart.\n.. As of the version [0.3.3](https://github.com/namkoong-lab/dro/releases/tag/v0.3.3)_ of their repository, those are implemented for specific cases:\n\n* for WDRO: only for linear models, and for specific neural networks under\n  $W_\\infty$ uncertainty (i.e. adversarial attacks, of the same flavor as\n  so-called \"*fast-gradient-sign attacks*\"),\n* for Sinkhorn-regularized-WDRO: only for linear models\n\n.. (even though to be fair, generalization of their interface to neural networks seems achievable at first glance).\n\nThis example notebook illustrates the use of the :class:`skwdro.linear_models.LinearRegression` side to side with the (KL-regularized or not) version of WDRO implemented by the python-dro library.\nThe aim is to illustrate the two libraries on the intersection of their application\ndomains.\n\n.. with similar hyperparameters settings, on a similar task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import timeit\nimport subprocess\nimport tqdm.auto as tqdm\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import check_X_y\n\nfrom dro.linear_model.wasserstein_dro import WassersteinDRO\nfrom dro.linear_model.sinkhorn_dro import SinkhornLinearDRO\nfrom skwdro.linear_models import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Total number of samples: chosen to be a bit prohibitive for SVM-like kernel methods (would deserve a separate analysis)\nn = 512\n# \"Low\"-dimensional setting to avoid this notebook to run for unreasonable amounts of time.\nd = 8\nn_train = int(np.floor(0.8 * n)) # Number of training samples: 80% of dataset\nn_test = n - n_train # Number of test samples\n\n# Generate some data\nX, y, *_ = make_regression(n_samples=n, n_features=d, noise=50, random_state=0)\nassert isinstance(X, np.ndarray)\n\n# Normalize the data\nX = minmax_scale(X, feature_range=(-1, 1))\ny = minmax_scale(y, feature_range=(-1, 1))\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n_train, test_size=n_test, random_state=0)\nassert isinstance(X_train, np.ndarray)\nassert isinstance(X_test, np.ndarray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Some more words on the setup\n\nFor reproducibility, we make notice of the fact that the results obtained\nbellow are obtained for a low number of runs, in order to reduce the time\nneeded to launch them.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>All benchmarks presented are run on CPU. GPU experiments are not\n   yet available.</p></div>\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This small script only works with unix-compatible\n   shells/distributions.</p></div>\n\nThese are the exact machine details:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for title, command in [\n    ('System spec.:', ['uname', '-mrs']),\n    ('Memory (RAM):', ['grep', 'MemTotal', '/proc/meminfo']),\n    ('CPU cores:', ['grep', 'model name', '/proc/cpuinfo']),\n    # ('CPU infos:', ['lshw', '-class', 'cpu', '-sanitize', '-notime'])\n]:\n    print(title)\n    _output = subprocess.run(command, stdout=subprocess.PIPE).stdout.decode('utf-8')\n    if 'CPU' in title:\n        print(*_output.split('model name\\t: '))\n    else:\n        print(_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WDRO linear regression\n\nBellow we define multiple models for the robust optimization of a\nlinear regression problem (OLS):\n\n* the non-regularized original WDRO formulation, cast as a convex optimization\n  problem for the 2-norm squared (i.e. $W_2$ measure transport cost,\n  for the Mahalanobis distance),\n* the regularized Sinkhorn-Wasserstein distance according to the two similar\n  approaches of Gao et al. [#WGX23]_ and\n  Azizian et al. [#AIM23]_ with regard to the way the problem is dualized,\n  both in the same hyperparameter settings.\n\n.. Those cases are treated in a low dimensional setting for ease of reproduction\n.. with the two libraries at hand.\n\n.. In terms of reproducibility, w\n\nWe set a few of the hyperparameters: the distance\nused for the ground-cost is the norm (squared) with unit metric tensor (\nimplying also an isotropic covariance matrix for the sampler), and no target\nswitches allowed.\nThe variance of the sampler is fixed, as well as the regularization parameter.\n\n.. Recall that the latter bears slightly different meanings in the two approaches,\n.. refer to the formula we present in\n.. [the Sinkhorn regularization tutorial](why_skwdro.html)_ as compared to the\n.. work of Gao [#WGX23]_.\n.. We set a fixed number of SGD iterations for the two libraries (5000 here, which\n.. seems to be enough).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rhos = [1e-6, 1e-3, 1e-1]\nSIGMA = 1e-2\nEPSILON_REGULARISATION = 1e-1\n\ndef fit_wdro_from_dro(rho: float):\n    estimator = WassersteinDRO(\n        input_dim=d,\n        solver='SCS',\n        model_type='ols'\n    )\n    estimator.update({\n        'cost_matrix': np.eye(d),\n        'eps': rho,\n        'p': 2,\n        'kappa': 'inf'\n    })\n    estimator.fit(*check_X_y(X_train, y_train))\n    return estimator\n\ndef fit_skwdro_from_dro(rho: float):\n    estimator = SinkhornLinearDRO(\n        input_dim=d,\n        fit_intercept=True,\n        max_iter=5_000,\n        reg_param=EPSILON_REGULARISATION,\n        model_type='ols'\n    )\n    estimator.update({\n        'cost_matrix': np.eye(d),\n        'eps': rho,\n        'p': 2,\n        'kappa': 'inf'\n    })\n    estimator.fit(*check_X_y(X_train, y_train))\n    return estimator\n\ndef fit_wdro_from_skwdro(rho: float):\n    estimator = LinearRegression(\n        solver='dedicated',\n        rho=rho,\n        fit_intercept=True\n    )\n    estimator.fit(X_train, y_train)\n    return estimator\n\ndef fit_skwdro_from_skwdro(rho: float):\n    estimator = LinearRegression(\n        rho=rho,\n        sampler_reg=SIGMA,\n        learning_rate=1e-3,\n        n_iter=5_000,\n        solver_reg=EPSILON_REGULARISATION,\n        fit_intercept=True\n    )\n    estimator.fit(X_train, y_train)\n    return estimator\n\nestimators_funcs = [\n    fit_wdro_from_dro,\n    fit_skwdro_from_dro,\n    fit_wdro_from_skwdro,\n    fit_skwdro_from_skwdro\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_train_errors = []\nall_test_errors = []\nall_timers = []\nmethod_names = [\n    'WDRO (p-dro)',\n    'Sk-WDRO (p-dro)',\n    'WDRO (skwdro)',\n    'Sk-WDRO (skwdro)'\n]\n\nfor rho in tqdm.tqdm(rhos, desc='Radii', position=0, leave=True):\n    train_errors = []\n    test_errors = []\n    timers = []\n\n    for fitter in tqdm.tqdm(estimators_funcs, desc='Method-score', leave=False, position=1):\n        estimator = fitter(rho)\n        train_errors.append(mean_squared_error(y_train, estimator.predict(X_train)))\n        test_errors.append(mean_squared_error(y_test, estimator.predict(X_test)))\n\n    all_train_errors.append(train_errors)\n    all_test_errors.append(test_errors)\n\n    for fn in [\n        'fit_wdro_from_dro',\n        'fit_skwdro_from_dro',\n        'fit_wdro_from_skwdro',\n        'fit_skwdro_from_skwdro'\n    ]:\n        timers.append(timeit.timeit(fn+'(rho)', globals=globals(), number=3))\n\n    all_timers.append(timers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n# Generic comparison plotting helper\n# Author: chat-gpt\n# ----------------------------------------------------------------------\n\ndef plot_library_comparison(\n    df: pd.DataFrame,\n    methods_python_dro: list,\n    methods_skwdro: list,\n    y_key: str,\n    title: str,\n    fname: str,\n    cmap_python='viridis',\n    cmap_skwdro='magma'\n):\n    \"\"\"\n    df: dataframe with columns ['rho', 'method', y_key]\n    methods_python_dro: methods to plot with square markers + dashed line\n    methods_skwdro: methods to plot with filled circle markers + solid line\n    y_key: 'test_error' or 'time'\n    \"\"\"\n\n    plt.figure(figsize=(10, 5))\n    ax = plt.gca()\n\n    # Create numeric x-axis from categorical rhos\n    x_vals = np.arange(df['rho'].nunique())\n    rho_labels = sorted(df['rho'].unique(), key=lambda x: int(x[5:-2]))  # sort by exponent\n    rho_to_x = {rho: i for i, rho in enumerate(rho_labels)}\n\n    # Build colormaps\n    cmap_py = plt.get_cmap(cmap_python, len(methods_python_dro))\n    cmap_sk = plt.get_cmap(cmap_skwdro, len(methods_skwdro))\n\n    # Python-DRO models \u2192 dashed lines + empty squares\n    for k, method in enumerate(methods_python_dro):\n        sub = df[df['method'] == method]\n        xs = [rho_to_x[r] for r in sub['rho']]\n        ys = sub[y_key].values\n        ax.plot(xs, ys,\n                linestyle='--',\n                marker='s',\n                markersize=10,\n                markerfacecolor='none',\n                markeredgecolor=cmap_py(k),\n                color=cmap_py(k),\n                linewidth=2,\n                label=f\"{method} (python-dro)\")\n\n    # SkWDRO models \u2192 solid lines + filled circles\n    for k, method in enumerate(methods_skwdro):\n        sub = df[df['method'] == method]\n        xs = [rho_to_x[r] for r in sub['rho']]\n        ys = sub[y_key].values\n        ax.plot(xs, ys,\n                linestyle='-',\n                marker='o',\n                markersize=9,\n                markerfacecolor=cmap_sk(k),\n                markeredgecolor=cmap_sk(k),\n                color=cmap_sk(k),\n                linewidth=2,\n                label=f\"{method} (skwdro)\")\n\n    ax.set_xticks(x_vals)\n    ax.set_xticklabels(rho_labels)\n    ax.set_yscale('log')\n    ax.set_xlabel(\"\u03c1 (Wasserstein radius)\")\n    ax.set_ylabel(y_key.replace('_', ' ').title())\n    ax.set_title(title)\n    ax.legend()\n    return ax\n\ndef _rho_formatter(rho: float) -> str:\n    return \"$10^{\" + f\"{int(np.log10(rho))}\" + \"}$\"\n\n# Build pandas DataFrames for seaborn (rho treated as categorical)\ntrain_df = pd.DataFrame([\n    {'rho': _rho_formatter(rhos[i]), 'method': method_names[j], 'train_error': all_train_errors[i][j]}\n        for i in range(len(rhos)) for j in range(len(method_names))\n])\n\ntest_df = pd.DataFrame([\n    {'rho': _rho_formatter(rhos[i]), 'method': method_names[j], 'test_error': all_test_errors[i][j]}\n        for i in range(len(rhos)) for j in range(len(method_names))\n])\n\ntime_df = pd.DataFrame([\n    {'rho': _rho_formatter(rhos[i]), 'method': method_names[j], 'time': all_timers[i][j]}\n        for i in range(len(rhos)) for j in range(len(method_names))\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WDRO comparison plots\nWe first propose a plot comparing disciplined WDRO implementations across\nlibraries.\nIt compares the test losses for the two methods, evaluated as the ERM (with\nmean-squared error), and the wall-clock running times.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wdro_methods = ['WDRO (p-dro)', 'WDRO (skwdro)']\nwdro_test = test_df[test_df['method'].isin(wdro_methods)]\nwdro_time = time_df[test_df['method'].isin(wdro_methods)]\nassert isinstance(wdro_test, pd.DataFrame)\nassert isinstance(wdro_time, pd.DataFrame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test loss plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_library_comparison(\n    df=wdro_test,\n    methods_python_dro=['WDRO (p-dro)'],\n    methods_skwdro=['WDRO (skwdro)'],\n    y_key='test_error',\n    title='WDRO Test Errors Across Libraries',\n    fname='/tmp/wdro_test_errors.png'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the two libraries are relatively similar, especially for small\nWasserstein radii, which is to be expected considering the similarity between\nthe implementations, based on the standard techniques of [#SaKE19]_ and\n[#EK17]_.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Timing plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_library_comparison(\n    df=wdro_time,\n    methods_python_dro=['WDRO (p-dro)'],\n    methods_skwdro=['WDRO (skwdro)'],\n    y_key='time',\n    title='WDRO Timing Across Libraries',\n    fname='/tmp/wdro_timing.png'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The running times of the two libraries are usually\ncomparable, even though it seems like the implementation in ``SkWDRO`` seems\nfaster in some setting.\n\n.. For fair comparison, we may impute this difference to the prior factorization\n.. that python-dro performs on the Mahalanobis metric (here the identity matrix),\n.. which is not handled by ``SkWDRO``. We argue that whitening the data prior to\n.. the optimization procedure might yield equivalent results in cases where this\n.. geometry is important, and on another hand that using the regularized\n.. formulation from our library would allow one to use the Mahalanobis distance\n.. as their transport cost (see the [costs tutorial](tutos/costs.html)_ for\n.. more details on how to do that).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SK-WDRO comparison plots\nHere is another set of plots comparing regularized WDRO\nimplementations, for the two libraries, both relying under the hood on\n``PyTorch``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare Sinkhorn-based WDRO models from both libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sk_methods = ['Sk-WDRO (p-dro)', 'Sk-WDRO (skwdro)']\nsk_test = test_df[test_df['method'].isin(sk_methods)]\nsk_time = time_df[test_df['method'].isin(sk_methods)]\nassert isinstance(sk_test, pd.DataFrame)\nassert isinstance(sk_time, pd.DataFrame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test loss plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_library_comparison(\n    df=sk_test,\n    methods_python_dro=['Sk-WDRO (p-dro)'],\n    methods_skwdro=['Sk-WDRO (skwdro)'],\n    y_key='test_error',\n    title='Sk-WDRO Test Errors Across Libraries',\n    fname='/tmp/skwdro_test_errors.png'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Timing plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_library_comparison(\n    df=sk_time,\n    methods_python_dro=['Sk-WDRO (p-dro)'],\n    methods_skwdro=['Sk-WDRO (skwdro)'],\n    y_key='time',\n    title='Sk-WDRO Timing Across Libraries',\n    fname='/tmp/skwdro_timing.png'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The speed of ``SkWDRO`` is usualy higher\nin this low dimensional setting with a medium-sized dataset.\nOther experiments could be run to show more balanced results with fewer samples\n(e.g. we obtained closer timings with $n=100$), or some times more\ndrastic difference of running time performance.\n\nFor the test accuracy though, it seems to depend heavily on the chosen\nrobustness radius: for smaller radii ``SkWDRO`` is more performant while\nthe technique from [#WGX23]_ is more suited for higher radii.\nWe have the intuition that this comes from the implementation in ``python-dro``\nwhich fixes the dual parameter $\\lambda$, removing the need to optimize\nit. In exchange, this forces the user to pick a good starting value for it.\nWe invite curious readers to tune it by hand for their code in order to see\nbetter and more radius-agnostic convergence properties.\n\n## Tackling non-linear models\n\nTo highlight the difference between ``SkWDRO`` and ``python-dro``, we argue\nthat our library's approach focuses on large parameters space models like\nneural networks that are not implementable in ``python-dro`` nor in other\nframeworks. This is illustrated in other tutorials in this documentation.\n\n### Neural nets on simple examples\n\nYou can first try our library on simpler low-dimensional examples that are\ntractable enough for obtaining quick and easy visual cues.\nThis is illustrated in more details in the\n[moons dataset example](examples/Custom/neural_net.html)_, in a simple two\ndimensional setting with a non-linearly-separable dataset.\n\n### Neural net on more difficult datasets\n\nThis approach scales to higher-dimensional settings,\nat the expense of computation time.\nWe showcase this on the [iWildsCam dataset](https://wilds.stanford.edu/)_,\nin a\n[separate documentation page](../../wilds.html)_.\n\n## References\n.. [#AIM23] Azizian, Iutzeler, and Malick: **Regularization for Wasserstein Distributionally Robust Optimization**, *COCV*, 2023\n.. [#WGX23] Wang, Gao, and Xie: **Sinkhorn Distributionally Robust Optimization**, *arXiv (2109.11926)*, 2023\n.. [#SaKE19] Shafieezadeh-Abadeh, Kuhn, and Esfahani: **Regularization via Mass Transportation**, *JMLR*, 2019\n.. [#EK17] Esfahani and Kuhn: **Data-Driven Distributionally Robust Optimization Using the Wasserstein Metric: Performance Guarentees and Tractable Reformulations**, *Mathematical Programming*, 2017\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}